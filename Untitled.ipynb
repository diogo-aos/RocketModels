{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# classify_image_graph_def.pb:\n",
    "#   Binary representation of the GraphDef protocol buffer.\n",
    "# imagenet_synset_to_human_label_map.txt:\n",
    "#   Map from synset ID to a human readable string.\n",
    "# imagenet_2012_challenge_label_map_proto.pbtxt:\n",
    "#   Text representation of a protocol buffer mapping a label to synset ID.\n",
    "parser.add_argument(\n",
    "    '--model_dir',\n",
    "    type=str,\n",
    "    default='/tmp/imagenet',\n",
    "    help=\"\"\"\\\n",
    "    Path to classify_image_graph_def.pb,\n",
    "    imagenet_synset_to_human_label_map.txt, and\n",
    "    imagenet_2012_challenge_label_map_proto.pbtxt.\\\n",
    "    \"\"\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--image_file',\n",
    "    type=str,\n",
    "    default='',\n",
    "    help='Absolute path to image file.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--num_top_predictions',\n",
    "    type=int,\n",
    "    default=5,\n",
    "    help='Display this many predictions.'\n",
    ")\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.image_file = '/rocketmodels/models/testimage.jpg'\n",
    "FLAGS.model_dir = '/rocketmodels/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    with tf.gfile.FastGFile(os.path.join(\n",
    "      FLAGS.model_dir, 'output_graphfourthmodel.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = tf.gfile.FastGFile(FLAGS.image_file, 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[100 120  69]\n",
      "  [ 98 118  67]\n",
      "  [ 96 116  65]\n",
      "  ...\n",
      "  [ 82  85  66]\n",
      "  [ 84  89  69]\n",
      "  [ 53  58  36]]\n",
      "\n",
      " [[ 97 117  66]\n",
      "  [ 98 118  67]\n",
      "  [ 97 117  66]\n",
      "  ...\n",
      "  [ 73  74  56]\n",
      "  [ 71  74  53]\n",
      "  [ 44  47  26]]\n",
      "\n",
      " [[ 94 112  62]\n",
      "  [ 97 115  65]\n",
      "  [ 98 116  66]\n",
      "  ...\n",
      "  [ 64  63  43]\n",
      "  [ 55  54  34]\n",
      "  [ 32  31  11]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 51  51  51]\n",
      "  [ 51  51  51]\n",
      "  [ 48  48  48]\n",
      "  ...\n",
      "  [ 47  47  47]\n",
      "  [ 52  52  52]\n",
      "  [ 51  51  51]]\n",
      "\n",
      " [[ 50  50  50]\n",
      "  [ 50  50  50]\n",
      "  [ 48  48  48]\n",
      "  ...\n",
      "  [ 49  49  49]\n",
      "  [ 51  51  51]\n",
      "  [ 50  50  50]]\n",
      "\n",
      " [[ 48  48  48]\n",
      "  [ 49  49  49]\n",
      "  [ 55  55  55]\n",
      "  ...\n",
      "  [ 57  57  57]\n",
      "  [ 49  49  49]\n",
      "  [ 48  48  48]]]\n"
     ]
    }
   ],
   "source": [
    "image = tf.image.decode_jpeg(image_file)\n",
    "# Start a new session to show example output.\n",
    "with tf.Session() as sess:\n",
    "    # Get an image tensor and print its value.\n",
    "    image_ary = sess.run([image])[0]\n",
    "    print(image_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_on_image(image):\n",
    "    \"\"\"Runs inference on an image.\n",
    "    Args:\n",
    "    image: Image file name.\n",
    "    Returns:\n",
    "    Nothing\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(image):\n",
    "        tf.logging.fatal('File does not exist %s', image)\n",
    "    image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "    \n",
    "    image = tf.image.decode_and_crop_jpeg(image_data, [0, 0, 299, 299])\n",
    "    # Start a new session to show example output.\n",
    "    with tf.Session() as sess:\n",
    "        # Get an image tensor and print its value.\n",
    "        image_ary = sess.run([image])\n",
    "\n",
    "    # Creates graph from saved GraphDef.\n",
    "    create_graph()\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print sess.graph.get_operations()[0].values()\n",
    "        print sess.graph.get_operations()[-1].values()\n",
    "    # Some useful tensors:\n",
    "    # 'softmax:0': A tensor containing the normalized prediction across\n",
    "    #   1000 labels.\n",
    "    # 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "    #   float description of the image.\n",
    "    # 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "    #   encoding of the image.\n",
    "    # Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "#         softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "#         predictions = sess.run(softmax_tensor,\n",
    "#                            {'DecodeJpeg/contents:0': image_data})\n",
    "        image = tf.image.decode_jpeg(image_data)\n",
    "        sess.run(image)\n",
    "        predictions = sess.run(softmax_tensor,\n",
    "                           {'Placeholder:0': image_ary})\n",
    "    \n",
    "        input_layer = \"input\"\n",
    "        input_name = \"import/\" + input_layer\n",
    "        input_operation = sess.graph.get_operation_by_name(input_name)\n",
    "        print(input_operation)\n",
    "\n",
    "        \n",
    "        predictions = np.squeeze(predictions)\n",
    "\n",
    "        # Creates node ID --> English string lookup.\n",
    "#         node_lookup = NodeLookup()\n",
    "\n",
    "        top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "        return predictions, top_k\n",
    "#         for node_id in top_k:\n",
    "#             human_string = node_lookup.id_to_string(node_id)\n",
    "#             score = predictions[node_id]\n",
    "#             print('%s (score = %.5f)' % (human_string, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'DecodeAndCropJpeg/contents:0' shape=() dtype=string>,)\n",
      "(<tf.Tensor 'final_result_2:0' shape=(?, 3) dtype=float32>,)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"The name 'import/input' refers to an Operation not in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ef65c466c0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_inference_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c13f4486bab8>\u001b[0m in \u001b[0;36mrun_inference_on_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0minput_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"import/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0minput_operation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_operation_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mget_operation_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3465\u001b[0m       raise TypeError(\"Operation names are strings (or similar), not %s.\" %\n\u001b[1;32m   3466\u001b[0m                       type(name).__name__)\n\u001b[0;32m-> 3467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_operation_by_name_unsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3341\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3398\u001b[0m           raise KeyError(\"The name %s refers to an Operation not in the \"\n\u001b[0;32m-> 3399\u001b[0;31m                          \"graph.\" % repr(name))\n\u001b[0m\u001b[1;32m   3400\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The name 'import/input' refers to an Operation not in the graph.\""
     ]
    }
   ],
   "source": [
    "run_inference_on_image(FLAGS.image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alert', 'anxious', 'frightened']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_labels('models/output_labelsfourthmodel.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_name,\n",
    "               input_height=299,\n",
    "               input_width=299,\n",
    "               input_mean=0,\n",
    "               input_std=255):\n",
    "    input_name = 'file_reader'\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(file_reader, channels=3, name=\"png_reader\")\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(normalized)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocess(FLAGS.image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sess.graph.get_operations()\n",
    "[m.values() for m in t][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph.get_operations()[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in l:\n",
    "    if 'Jpeg' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph_def.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = FLAGS.image_file\n",
    "\n",
    "if not tf.gfile.Exists(image):\n",
    "    tf.logging.fatal('File does not exist %s', image)\n",
    "image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "# Creates graph from saved GraphDef.\n",
    "create_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "# Some useful tensors:\n",
    "# 'softmax:0': A tensor containing the normalized prediction across\n",
    "#   1000 labels.\n",
    "# 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "#   float description of the image.\n",
    "# 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "#   encoding of the image.\n",
    "# Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    predictions = sess.run(softmax_tensor,\n",
    "                       {'DecodeJpeg/contents:0': image_data})\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    # Creates node ID --> English string lookup.\n",
    "    node_lookup = NodeLookup()\n",
    "\n",
    "    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "    for node_id in top_k:\n",
    "        human_string = node_lookup.id_to_string(node_id)\n",
    "        score = predictions[node_id]\n",
    "        print('%s (score = %.5f)' % (human_string, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
