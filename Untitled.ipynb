{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# classify_image_graph_def.pb:\n",
    "#   Binary representation of the GraphDef protocol buffer.\n",
    "# imagenet_synset_to_human_label_map.txt:\n",
    "#   Map from synset ID to a human readable string.\n",
    "# imagenet_2012_challenge_label_map_proto.pbtxt:\n",
    "#   Text representation of a protocol buffer mapping a label to synset ID.\n",
    "parser.add_argument(\n",
    "    '--model_dir',\n",
    "    type=str,\n",
    "    default='/tmp/imagenet',\n",
    "    help=\"\"\"\\\n",
    "    Path to classify_image_graph_def.pb,\n",
    "    imagenet_synset_to_human_label_map.txt, and\n",
    "    imagenet_2012_challenge_label_map_proto.pbtxt.\\\n",
    "    \"\"\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--image_file',\n",
    "    type=str,\n",
    "    default='',\n",
    "    help='Absolute path to image file.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--num_top_predictions',\n",
    "    type=int,\n",
    "    default=5,\n",
    "    help='Display this many predictions.'\n",
    ")\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.image_file = '/rocketmodels/models/testimage.jpg'\n",
    "FLAGS.model_dir = '/rocketmodels/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    with tf.gfile.FastGFile(os.path.join(\n",
    "      FLAGS.model_dir, 'output_graphfourthmodel.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = tf.gfile.FastGFile(FLAGS.image_file, 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[100 120  69]\n",
      "  [ 98 118  67]\n",
      "  [ 96 116  65]\n",
      "  ...\n",
      "  [ 82  85  66]\n",
      "  [ 84  89  69]\n",
      "  [ 53  58  36]]\n",
      "\n",
      " [[ 97 117  66]\n",
      "  [ 98 118  67]\n",
      "  [ 97 117  66]\n",
      "  ...\n",
      "  [ 73  74  56]\n",
      "  [ 71  74  53]\n",
      "  [ 44  47  26]]\n",
      "\n",
      " [[ 94 112  62]\n",
      "  [ 97 115  65]\n",
      "  [ 98 116  66]\n",
      "  ...\n",
      "  [ 64  63  43]\n",
      "  [ 55  54  34]\n",
      "  [ 32  31  11]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 51  51  51]\n",
      "  [ 51  51  51]\n",
      "  [ 48  48  48]\n",
      "  ...\n",
      "  [ 47  47  47]\n",
      "  [ 52  52  52]\n",
      "  [ 51  51  51]]\n",
      "\n",
      " [[ 50  50  50]\n",
      "  [ 50  50  50]\n",
      "  [ 48  48  48]\n",
      "  ...\n",
      "  [ 49  49  49]\n",
      "  [ 51  51  51]\n",
      "  [ 50  50  50]]\n",
      "\n",
      " [[ 48  48  48]\n",
      "  [ 49  49  49]\n",
      "  [ 55  55  55]\n",
      "  ...\n",
      "  [ 57  57  57]\n",
      "  [ 49  49  49]\n",
      "  [ 48  48  48]]]\n"
     ]
    }
   ],
   "source": [
    "image = tf.image.decode_jpeg(image_file)\n",
    "# Start a new session to show example output.\n",
    "with tf.Session() as sess:\n",
    "    # Get an image tensor and print its value.\n",
    "    image_ary = sess.run([image])[0]\n",
    "    print(image_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_on_image(image):\n",
    "    \"\"\"Runs inference on an image.\n",
    "    Args:\n",
    "    image: Image file name.\n",
    "    Returns:\n",
    "    Nothing\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(image):\n",
    "        tf.logging.fatal('File does not exist %s', image)\n",
    "    image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "    \n",
    "    image = tf.image.decode_and_crop_jpeg(image_data, [0, 0, 299, 299])\n",
    "    # Start a new session to show example output.\n",
    "    with tf.Session() as sess:\n",
    "        # Get an image tensor and print its value.\n",
    "        image_ary = sess.run([image])\n",
    "\n",
    "    # Creates graph from saved GraphDef.\n",
    "    create_graph()\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print sess.graph.get_operations()[0].values()\n",
    "        print sess.graph.get_operations()[-1].values()\n",
    "    # Some useful tensors:\n",
    "    # 'softmax:0': A tensor containing the normalized prediction across\n",
    "    #   1000 labels.\n",
    "    # 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "    #   float description of the image.\n",
    "    # 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "    #   encoding of the image.\n",
    "    # Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "#         softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "#         predictions = sess.run(softmax_tensor,\n",
    "#                            {'DecodeJpeg/contents:0': image_data})\n",
    "        image = tf.image.decode_jpeg(image_data)\n",
    "        sess.run(image)\n",
    "        predictions = sess.run(softmax_tensor,\n",
    "                           {'Placeholder:0': image_ary})\n",
    "\n",
    "        \n",
    "        predictions = np.squeeze(predictions)\n",
    "\n",
    "        # Creates node ID --> English string lookup.\n",
    "#         node_lookup = NodeLookup()\n",
    "\n",
    "        top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "        return predictions, top_k\n",
    "#         for node_id in top_k:\n",
    "#             human_string = node_lookup.id_to_string(node_id)\n",
    "#             score = predictions[node_id]\n",
    "#             print('%s (score = %.5f)' % (human_string, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'Placeholder:0' shape=(?, 299, 299, 3) dtype=float32>,)\n",
      "(<tf.Tensor 'final_result_14:0' shape=(?, 3) dtype=float32>,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0.], dtype=float32), array([0, 2, 1]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_inference_on_image(FLAGS.image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sess.graph.get_operations()\n",
    "[m.values() for m in t][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph.get_operations()[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in l:\n",
    "    if 'Jpeg' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph_def.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = FLAGS.image_file\n",
    "\n",
    "if not tf.gfile.Exists(image):\n",
    "    tf.logging.fatal('File does not exist %s', image)\n",
    "image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "# Creates graph from saved GraphDef.\n",
    "create_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "# Some useful tensors:\n",
    "# 'softmax:0': A tensor containing the normalized prediction across\n",
    "#   1000 labels.\n",
    "# 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "#   float description of the image.\n",
    "# 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "#   encoding of the image.\n",
    "# Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    predictions = sess.run(softmax_tensor,\n",
    "                       {'DecodeJpeg/contents:0': image_data})\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    # Creates node ID --> English string lookup.\n",
    "    node_lookup = NodeLookup()\n",
    "\n",
    "    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "    for node_id in top_k:\n",
    "        human_string = node_lookup.id_to_string(node_id)\n",
    "        score = predictions[node_id]\n",
    "        print('%s (score = %.5f)' % (human_string, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
