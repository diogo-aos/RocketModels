{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "# classify_image_graph_def.pb:\n",
    "#   Binary representation of the GraphDef protocol buffer.\n",
    "# imagenet_synset_to_human_label_map.txt:\n",
    "#   Map from synset ID to a human readable string.\n",
    "# imagenet_2012_challenge_label_map_proto.pbtxt:\n",
    "#   Text representation of a protocol buffer mapping a label to synset ID.\n",
    "parser.add_argument(\n",
    "    '--model_dir',\n",
    "    type=str,\n",
    "    default='/tmp/imagenet',\n",
    "    help=\"\"\"\\\n",
    "    Path to classify_image_graph_def.pb,\n",
    "    imagenet_synset_to_human_label_map.txt, and\n",
    "    imagenet_2012_challenge_label_map_proto.pbtxt.\\\n",
    "    \"\"\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--image_file',\n",
    "    type=str,\n",
    "    default='',\n",
    "    help='Absolute path to image file.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--num_top_predictions',\n",
    "    type=int,\n",
    "    default=5,\n",
    "    help='Display this many predictions.'\n",
    ")\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS.image_file = '/rocketmodels/models/testimage.jpg'\n",
    "FLAGS.model_dir = '/rocketmodels/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(model_file):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "\n",
    "    with open(model_file, \"rb\") as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n",
    "    # Creates graph from saved graph_def.pb.\n",
    "    with tf.gfile.FastGFile(os.path.join(\n",
    "      FLAGS.model_dir, 'output_graphAlertAnxiousFright.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = tf.gfile.FastGFile(FLAGS.image_file, 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[100 120  69]\n",
      "  [ 98 118  67]\n",
      "  [ 96 116  65]\n",
      "  ...\n",
      "  [ 82  85  66]\n",
      "  [ 84  89  69]\n",
      "  [ 53  58  36]]\n",
      "\n",
      " [[ 97 117  66]\n",
      "  [ 98 118  67]\n",
      "  [ 97 117  66]\n",
      "  ...\n",
      "  [ 73  74  56]\n",
      "  [ 71  74  53]\n",
      "  [ 44  47  26]]\n",
      "\n",
      " [[ 94 112  62]\n",
      "  [ 97 115  65]\n",
      "  [ 98 116  66]\n",
      "  ...\n",
      "  [ 64  63  43]\n",
      "  [ 55  54  34]\n",
      "  [ 32  31  11]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 51  51  51]\n",
      "  [ 51  51  51]\n",
      "  [ 48  48  48]\n",
      "  ...\n",
      "  [ 47  47  47]\n",
      "  [ 52  52  52]\n",
      "  [ 51  51  51]]\n",
      "\n",
      " [[ 50  50  50]\n",
      "  [ 50  50  50]\n",
      "  [ 48  48  48]\n",
      "  ...\n",
      "  [ 49  49  49]\n",
      "  [ 51  51  51]\n",
      "  [ 50  50  50]]\n",
      "\n",
      " [[ 48  48  48]\n",
      "  [ 49  49  49]\n",
      "  [ 55  55  55]\n",
      "  ...\n",
      "  [ 57  57  57]\n",
      "  [ 49  49  49]\n",
      "  [ 48  48  48]]]\n"
     ]
    }
   ],
   "source": [
    "image = tf.image.decode_jpeg(image_file)\n",
    "# Start a new session to show example output.\n",
    "with tf.Session() as sess:\n",
    "    # Get an image tensor and print its value.\n",
    "    image_ary = sess.run([image])[0]\n",
    "    print(image_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_on_image(image):\n",
    "    \"\"\"Runs inference on an image.\n",
    "    Args:\n",
    "    image: Image file name.\n",
    "    Returns:\n",
    "    Nothing\n",
    "    \"\"\"\n",
    "    if not tf.gfile.Exists(image):\n",
    "        tf.logging.fatal('File does not exist %s', image)\n",
    "    image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "    \n",
    "    image = tf.image.decode_and_crop_jpeg(image_data, [0, 0, 299, 299])\n",
    "    # Start a new session to show example output.\n",
    "    with tf.Session() as sess:\n",
    "        # Get an image tensor and print its value.\n",
    "        image_ary = sess.run([image])\n",
    "\n",
    "    # Creates graph from saved GraphDef.\n",
    "    create_graph()\n",
    "    \n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        input_layer = \"Placeholder\"                                                                                                                                 \n",
    "        output_layer = \"final_result\"  \n",
    "        input_name = \"import/\" + input_layer                                                                                                                \n",
    "        output_name = \"import/\" + output_layer\n",
    "        input_name = input_layer\n",
    "        output_name = output_layer\n",
    "        input_operation = sess.graph.get_operation_by_name(input_name)                                                                                           \n",
    "        output_operation = sess.graph.get_operation_by_name(output_name)\n",
    "        \n",
    "        print output_operation.outputs[0]\n",
    "        print input_operation.outputs[0]\n",
    "        \n",
    "        print sess.graph.get_operations()[0].outputs\n",
    "        print sess.graph.get_operations()[-1].values()\n",
    "    # Some useful tensors:\n",
    "    # 'softmax:0': A tensor containing the normalized prediction across\n",
    "    #   1000 labels.\n",
    "    # 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "    #   float description of the image.\n",
    "    # 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "    #   encoding of the image.\n",
    "    # Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "#         softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "#         predictions = sess.run(softmax_tensor,\n",
    "#                            {'DecodeJpeg/contents:0': image_data})\n",
    "        image = tf.image.decode_jpeg(image_data)\n",
    "        image_ary = sess.run(image)[0]\n",
    "#         predictions = sess.run(softmax_tensor,\n",
    "#                            {'Placeholder:0': image_ary})\n",
    "    \n",
    "        results = sess.run(output_operation.outputs[0], {input_operation.outputs[0]: image_ary}) \n",
    "        \n",
    "        predictions = np.squeeze(predictions)\n",
    "\n",
    "        # Creates node ID --> English string lookup.\n",
    "#         node_lookup = NodeLookup()\n",
    "\n",
    "        top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "        return predictions, top_k\n",
    "#         for node_id in top_k:\n",
    "#             human_string = node_lookup.id_to_string(node_id)\n",
    "#             score = predictions[node_id]\n",
    "#             print('%s (score = %.5f)' % (human_string, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"final_result:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 299, 299, 3), dtype=float32)\n",
      "[<tf.Tensor 'DecodeAndCropJpeg/contents:0' shape=() dtype=string>]\n",
      "(<tf.Tensor 'final_result_9:0' shape=(?, 3) dtype=float32>,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (800, 3) for Tensor u'Placeholder:0', which has shape '(?, 299, 299, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ef65c466c0bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_inference_on_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-b70b804a7738>\u001b[0m in \u001b[0;36mrun_inference_on_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#                            {'Placeholder:0': image_ary})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_operation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_operation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_ary\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1076\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (800, 3) for Tensor u'Placeholder:0', which has shape '(?, 299, 299, 3)'"
     ]
    }
   ],
   "source": [
    "run_inference_on_image(FLAGS.image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    label = []\n",
    "    proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "    for l in proto_as_ascii_lines:\n",
    "        label.append(l.rstrip())\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alert', 'anxious', 'frightened']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_labels('models/output_labelsfourthmodel.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_name,\n",
    "               input_height=299,\n",
    "               input_width=299,\n",
    "               input_mean=0,\n",
    "               input_std=255):\n",
    "    input_name = 'file_reader'\n",
    "    file_reader = tf.read_file(file_name, input_name)\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(file_reader, channels=3, name=\"png_reader\")\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(tf.image.decode_gif(file_reader, name=\"gif_reader\"))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name=\"bmp_reader\")\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(file_reader, channels=3, name=\"jpeg_reader\")\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    with tf.Session() as sess:\n",
    "        result = sess.run(normalized)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_data = preprocess(FLAGS.image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"final_result:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"Placeholder:0\", shape=(?, 299, 299, 3), dtype=float32)\n",
      "[<tf.Tensor 'DecodeAndCropJpeg/contents:0' shape=() dtype=string>]\n",
      "(<tf.Tensor 'final_result_10:0' shape=(?, 3) dtype=float32>,)\n"
     ]
    }
   ],
   "source": [
    "# Creates graph from saved GraphDef.\n",
    "create_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    input_layer = \"Placeholder\"                                                                                                                                 \n",
    "    output_layer = \"final_result\"  \n",
    "    input_name = \"import/\" + input_layer                                                                                                                \n",
    "    output_name = \"import/\" + output_layer\n",
    "    input_name = input_layer\n",
    "    output_name = output_layer\n",
    "    input_operation = sess.graph.get_operation_by_name(input_name)                                                                                           \n",
    "    output_operation = sess.graph.get_operation_by_name(output_name)\n",
    "\n",
    "    print output_operation.outputs[0]\n",
    "    print input_operation.outputs[0]\n",
    "\n",
    "    print sess.graph.get_operations()[0].outputs\n",
    "    print sess.graph.get_operations()[-1].values()\n",
    "\n",
    "    results = sess.run(output_operation.outputs[0], {input_operation.outputs[0]: im_data}) \n",
    "\n",
    "    predictions = np.squeeze(results)\n",
    "\n",
    "    # Creates node ID --> English string lookup.\n",
    "#         node_lookup = NodeLookup()\n",
    "\n",
    "    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocess(FLAGS.image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sess.graph.get_operations()\n",
    "[m.values() for m in t][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph.get_operations()[0].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in l:\n",
    "    if 'Jpeg' in line:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.graph_def.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = FLAGS.image_file\n",
    "\n",
    "if not tf.gfile.Exists(image):\n",
    "    tf.logging.fatal('File does not exist %s', image)\n",
    "image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "# Creates graph from saved GraphDef.\n",
    "create_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "# Some useful tensors:\n",
    "# 'softmax:0': A tensor containing the normalized prediction across\n",
    "#   1000 labels.\n",
    "# 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "#   float description of the image.\n",
    "# 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "#   encoding of the image.\n",
    "# Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "    predictions = sess.run(softmax_tensor,\n",
    "                       {'DecodeJpeg/contents:0': image_data})\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    # Creates node ID --> English string lookup.\n",
    "    node_lookup = NodeLookup()\n",
    "\n",
    "    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "    for node_id in top_k:\n",
    "        human_string = node_lookup.id_to_string(node_id)\n",
    "        score = predictions[node_id]\n",
    "        print('%s (score = %.5f)' % (human_string, score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
